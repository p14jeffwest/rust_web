한자를 한글로 변환하는 데 있어 가장 기본이 될 함수는 `convert_str`이다. 주어진 문자열을 한글로 변환할 것이다. 

라이브러리 함수로도 사용할 것이기에 `lib.rs`에 만들 것이다. 

## lib.rs 파일 생성하기

vs code를 열어서 src 폴더 밑에 lib.rs 파일을 생성한다. lib.rs 파일에 convert_str 함수를 만들 것이다. 

## convert_str 함수 설계 

함수의 형태를 이렇게 할 것이다. 

```rust
pub fn convert_str(
    input_str:&str,         
    char_dic:&HashMap<char,char>, 
    dueum_dic:&HashMap<char,char>,
    word_dic:&HashMap<String, String>) -> Option<String>{
```

한자 문자열이 있는 `input_str`을 받을 것이고, 한자 변환 사전을 HashMap 형태로 받을 것이다.   
그리고, 이렇게 받은 입력값을 한글로 변환해서 `Option(String)`으로 리턴할 것이다. 

> `Option(String)`으로 리턴한다는 것은, 변환에 성공하면 `Ok(String)`으로 리턴하고, 그렇지 않으면 `None`으로 리턴하겠다는 것이다. `Result`로 리턴하지 않고 `Option`으로 하는 것은, 주어진 문자열에 대해서 한글로 변환하지 못하더라도 에러를 내지는 않고 그냥 `None`으로 처리하겠다는 것이다. 만약 `Result`를 리턴하게 되면, 변환에 실패했을 때 Error를 리턴하고, 일반적으로 Error가 났을 때 프로그램을 종료하는 panic을 발생하기에, 그렇게 하지 않겠다는 것이다.   

그런데, 이 함수를 호출하려면 한자로 된 문자열뿐 아니라, HahsMap으로 된 한자 사전 3개가 이미 만들어져 있어야 한다. 이 3개의 사전에 해당하는 HashMap을 먼저 만드는 함수를 만들자. 

## load_dictionary 함수 만들기

한자-한글에 대한 기본 사전, 두음법칙 사전, 불규칙 변환 사전을 HashMap으로 만들어 리턴하는 load_dictionary 함수를 만들 것이다. 

#### 어떻게 만들지에 대한 고민

변환 데이터가 꽤 크다. 

데이터를 csv 파일로 두고 이를 읽어들여서 HashMap으로 만드는 것이 한 방법이다. 
그런데, 이 경우는 이 csv 파일들이 같이 있는 상태에서 프로그램을 동작해야하는 번거러움이 있다. 

여기서는 데이터를 문자열 상수로 저장해 놓고, load_dictionary를 호출하면 그 문자열로부터 HashMap을 만들어내는 방법을 사용할 것이다. 

#### 데이터 파일

hanja_char.rs 파일에는 기본 한자-한글 변환 데이터를 둔다. 

아래와 같은 형태다. 

```rust
pub const HANJA_BASIC:&str = 
r#"伽,가
佳,가
假,가
價,가
加,가
...

"#;
```

> 문자열을 정의할 때 `r`은 `raw string literal`을 나타내는 예약어이고, `#"`과 `"#`사이에 있는 문자열 안에 있는 모든 문자를 일반 문자로 처리하겠다는 의미다. 즉, 문자열 안에 `\`라던가 `"`기 있어도 이것을 특수한 의미를 가지는 예약어가 아니라 일반 문자로 취급하겠다는 의미다.  
> 여기서는 문자열 안에 줄바꿈 문자인 `\n`이 있어서 `r#`을 사용했다. 

마찬가지로 두음법칙용 데이터 파일로 `dueum.rs`와 불규칙 변환용 단어 파일로 `hanja_word.rs`를 만든다. 


```rust
//dueum.rs
pub const DUEUM: &str = 
r#"냑,약
냥,양
녀,여
녁,역
...

```



```rust
//hanja_word.rs
pub const HANJA_SPECIAL:&str = 
r#"客車,객차
車庫,차고
金氏,김씨
大保,태보
大僕,태복
...
```

#### 데이터 이용해서 HashMap 사전 만들기 

소스가 되는 데이터는 콤마로 값이 구분된 문자열이다. 해서 csv를 다루는 패키지로 값을 읽어낼 수도 있으나, 그냥 날코딩을 해도 간단히 데이터를 뽑아낼 수 있다. 

먼저 `HANJA_BASIC`의 경우는 하나의 줄에 `<한자>,<한글 음>`이 있는 구조이기에, 한 줄씩 읽으면서 그 안에서 <한자>와 <한글>을 분리해서 HashMap에 담으면 되겠다. 

```rust
    let char_dic = hanja_char::HANJA_BASIC.lines()
        .filter_map(|line| {
            let parts: Vec<&str> = line.split(',').collect();
            if parts.len() == 2 {
                let key_char = [[MARK]]parts[0].trim().chars()[[/MARK]].next().unwrap();
                let val_char = [[MARK]]parts[1].trim().chars()[[/MARK]].next().unwrap();
                Some((key_char, val_char))
            } else {
                None
            }
        })
        .collect::<HashMap<char, char>>();
```

여기서 주의할 것은 `HashMap<char, char>`으로 데이터를 처리했다는 점이다. 한 개 한자에 대해 하나의 한글 음이 대응되는 구조이기에, 하나의 char로 각각 처리했다.  

두음법칙에 해당하는 `DUEUM` 데이터를 처리하는 것도 동일한 구조다. 

```rust
    let dueum_dic = dueum::DUEUM.lines()
        .filter_map(|line| {
            let parts: Vec<&str> = line.split(',').collect();
            if parts.len() == 2 {
                let key_char = parts[0].trim().chars().next().unwrap();
                let val_char = parts[1].trim().chars().next().unwrap();
                Some((key_char, val_char))
            } else {
                None
            }
        })
        .collect::<HashMap<char, char>>();
```

불규칙 변환을 하는 단어들을 모아놓은 `HANJA_SPECIAL`을 처리하는 것은 좀 다르다. `<char, char>`가 아니고, `<string, string>`으로 처리한다. 콤마로 구분된 값이 하나의 문자가 아니고 문자열이기 때문이다. 

```rust
let word_dic = hanja_word::HANJA_SPECIAL.lines()
        .filter_map(|line| {
            let parts: Vec<&str> = line.split(',').collect();
            if parts.len() == 2 {
                let key_str = parts[0].trim().to_string();
                let val_str = parts[1].trim().to_string();
                Some((key_str, val_str))
            } else {
                None
            }
        })
        .collect::<HashMap<String, String>>();  
```

이렇게 3가지 데이터를 각각 HashMap 객체로 만들어서 리턴하는 함수가 `load_dictionary` 함수다. 

```rust
pub fn load_dictionary() 
        -> Result<(HashMap<char, char>, HashMap<char, char>, HashMap<String, String>), Box<dyn Error>> {
    
    //1. 기본한자 변환 사전
    let char_dic = hanja_char::HANJA_BASIC.lines()
        .filter_map(|line| {
            let parts: Vec<&str> = line.split(',').collect();
            if parts.len() == 2 {
                let key_char = parts[0].trim().chars().next().unwrap();
                let val_char = parts[1].trim().chars().next().unwrap();
                Some((key_char, val_char))
            } else {
                None
            }
        })
        .collect::<HashMap<char, char>>();


    //2. 두음법칙 사전
    //dueum::DUEUM은 ("냥,양\n") 형태의 여러 라인으로 구성되어 있다. 
    //모든 라인을 읽고, 각 라인 별로 콤마를 기준으로 split하여, 앞 문자와 뒤 문자를 각각 key와 value로 설정한다.
    //이때, key와 value는 모두 char로 변환하여 저장한다.
    let dueum_dic = dueum::DUEUM.lines()
        .filter_map(|line| {
            let parts: Vec<&str> = line.split(',').collect();
            if parts.len() == 2 {
                let key_char = parts[0].trim().chars().next().unwrap();
                let val_char = parts[1].trim().chars().next().unwrap();
                Some((key_char, val_char))
            } else {
                None
            }
        })
        .collect::<HashMap<char, char>>();

    //3. 불규칙 변환 한자사전
    // hanja_word::HANJA_SPECIAL은 ("女子,여자\n") 형태의 여러 라인으로 구성되어 있다.
    //모든 라인을 읽고, 각 라인 별로 콤마를 기준으로 split하여, 앞 문자와 뒤 문자를 각각 key와 value로 설정한다.
    //이때, key와 value는 모두 String으로 변환하여 저장한다.
    let word_dic = hanja_word::HANJA_SPECIAL.lines()
        .filter_map(|line| {
            let parts: Vec<&str> = line.split(',').collect();
            if parts.len() == 2 {
                let key_str = parts[0].trim().to_string();
                let val_str = parts[1].trim().to_string();
                Some((key_str, val_str))
            } else {
                None
            }
        })
        .collect::<HashMap<String, String>>();  

    Ok((char_dic, dueum_dic, word_dic))
}
```

## convert_str 함수 만들기 

다시 convert_str 함수를 어떻게 만들건지로 돌아오면, 위에서 convert_str 함수의 모양은 아래와 같이 설계했었다. 

```rust
pub fn convert_str(
    input_str:&str,         
    char_dic:&HashMap<char,char>, 
    dueum_dic:&HashMap<char,char>,
    word_dic:&HashMap<String, String>) -> Option<String>
```

convert_str 함수를 호출하는 데 필요한 HashMap 3개는 위에서 만든 load_dictionary 함수로 만들 수 있기에, 이제 이 convert_str을 구현하기만 하면 되겠다. 

구현 로직은 간단하다. 

1. 입력으로 주어진 한자가 포함된 문자열에서 문자 배열을 뽑아내고,  
2. 문자 배열의 인덱스를 증가시키면서 모든 문자에 대해 검사해 나가면서,    
    2-1. 먼저, 현재 위치에 순수 한자로 된 단어가 있다면 뽑아내고,  
    2-2. 이 한자어 단어가 불규칙 변환 사전인 `word_dic`에 있는 단어라면 불규칙변환에 따라 변환한다.   
    2-3. 위 2-1 루틴에 이어, 만약 단어가 아닌 하나의 문자라면 해당 문자를 뽑아낸다.  
    2-4. 위 2-3에서 뽑아낸 문자가 '한자'라면 기본사전을 이용해서 한글로 변환한다.  
    2-5. 위 2-4에서 변환한 문자 다음에 다른 문자가 있고, 변환했던 한자가 '두음법칙' 적용되는 한자이면 '두음법칙'을 적용하여 다시 변경한다.  

위 로직을 수행할 때 2-1에서 해당 문자가 '한자'인지 아닌지를 판단해야 하는 부분이 있다. 해당 문자가 한자인지 아닌지는 해당 문자의 unicode가 '한자'가 위치한 범위인지를 보면 된다. 

한자 코드 범위는 다음과 같다. 

* 13312 ~ 19893: 6,582개
* 19968 ~ 40869: 20,902개
* 63744 ~ 64045: 302개
* 64048 ~ 64109: 62개

이것을 프로그램에서 상수로 정의해 둔다. 

```rust
const CHI_S1:u32 = 13312;
const CHI_E1:u32 = 19903;

const CHI_S2:u32 = 19968;
const CHI_E2:u32 = 40959;

const CHI_S3:u32 = 63744;
const CHI_E3:u32 = 64045;

const CHI_S4:u32 = 64048;
const CHI_E4:u32 = 64109;
```

이제 위 정보를 이용해서, '한자'인지를 판별하는 함수 `is_chi`를 아래와 같이 만들 수 있겠다. 

```rust
fn is_chi(c:&char) -> bool {
    let n = *c as u32;
    if  (n >= CHI_S1 && n <= CHI_E1) || (n >= CHI_S2 && n <= CHI_E2) || 
        (n >= CHI_S3 && n <= CHI_E3) || (n >= CHI_S4 && n <= CHI_E4) { 
        true 
    }else { false }  
}
```

또한 위 로직 2-4에서, 어떤 문자가 있고 그다음에 한글 혹은 한자 문자가 오는지를 판단해야 하는 부분이 있는데, 여기서 어떤 문자가 공백이나 특수문자가 아니고 '한글' 혹은 '한자'인지를 판단하는 것은, 역시 해당 문자의 코드가 '한자' 혹은 '한글' 코드 영역에 있는지를 보면 되겠다. 

한글 코드 영역은, 

```rust
const KO_START:u32 = 44032;
const KO_END:u32 = 55203;
```

```rust
fn is_kor_or_chi(c:&char) -> bool {
    let n = *c as u32;
    if (n >= KO_START && n <= KO_END) || 
       ( (n >= CHI_S1 && n <= CHI_E1) || (n >= CHI_S2 && n <= CHI_E2) || 
         (n >= CHI_S3 && n <= CHI_E3) || (n >= CHI_S4 && n <= CHI_E4)) {
        true
    }else {
        false
    }    
}
```

------

위에서 public 함수인 `load_dictionary`와 `convert_str`과 내부 함수인 `is_chi`와 `is_koor_or_char` 함수를 만들었다. 

이것을 모두 `src/lib.rs`에 작성하면 되겠다. 아래는 lib.rs 파일에 작성된 코드 내용이다. 

또한, 이 lib.rs에 있는 함수들을 테스트해보는 코드는 `src/main.rs`에서 만들어 볼 수 있겠다. 

```rust
// src/main.rs


fn main() {
    let hanja_str = 
    "「宋寅壽기자」14일 농림해양수산위의 농협 국감에선 올해 추곡수매와 농산물시장 개방에 따른 대책 등이 주요 쟁점으로 대두됐다. 
 
客車, 六月, 庫間, 女子
 
金泳鎭(국민회의) 韓灝鮮(자민련) 權五乙의원(민주당)은 ......";

    let (char_dic, dueum_dic, word_dic) = rust_web::load_dictionary().expect("사전 로드 실패");
    let hangul_str = rust_web::convert_str(hanja_str, &char_dic, &dueum_dic, &word_dic).unwrap();
    println!("변환된 문자열: \n {}", hangul_str);        
}
```


```rust
// src/lib.rs 

mod hanja_char;
mod hanja_word;
mod dueum;

use std::{collections::HashMap, error::Error};

const KO_START:u32 = 44032;
const KO_END:u32 = 55203;

const CHI_S1:u32 = 13312;
const CHI_E1:u32 = 19903;

const CHI_S2:u32 = 19968;
const CHI_E2:u32 = 40959;

const CHI_S3:u32 = 63744;
const CHI_E3:u32 = 64045;

const CHI_S4:u32 = 64048;
const CHI_E4:u32 = 64109;


pub fn load_dictionary() 
        -> Result<(HashMap<char, char>, HashMap<char, char>, HashMap<String, String>), Box<dyn Error>> {
    
    //1. 기본한자 변환 사전
    let char_dic = hanja_char::HANJA_BASIC.lines()
        .filter_map(|line| {
            let parts: Vec<&str> = line.split(',').collect();
            if parts.len() == 2 {
                let key_char = parts[0].trim().chars().next().unwrap();
                let val_char = parts[1].trim().chars().next().unwrap();
                Some((key_char, val_char))
            } else {
                None
            }
        })
        .collect::<HashMap<char, char>>();


    //2. 두음법칙 사전
    //dueum::DUEUM은 ("냥,양\n") 형태의 여러 라인으로 구성되어 있다. 
    //모든 라인을 읽고, 각 라인 별로 콤마를 기준으로 split하여, 앞 문자와 뒤 문자를 각각 key와 value로 설정한다.
    //이때, key와 value는 모두 char로 변환하여 저장한다.
    let dueum_dic = dueum::DUEUM.lines()
        .filter_map(|line| {
            let parts: Vec<&str> = line.split(',').collect();
            if parts.len() == 2 {
                let key_char = parts[0].trim().chars().next().unwrap();
                let val_char = parts[1].trim().chars().next().unwrap();
                Some((key_char, val_char))
            } else {
                None
            }
        })
        .collect::<HashMap<char, char>>();

    //3. 불규칙 변환 한자사전
    // hanja_word::HANJA_SPECIAL은 ("女子,여자\n") 형태의 여러 라인으로 구성되어 있다.
    //모든 라인을 읽고, 각 라인 별로 콤마를 기준으로 split하여, 앞 문자와 뒤 문자를 각각 key와 value로 설정한다.
    //이때, key와 value는 모두 String으로 변환하여 저장한다.
    let word_dic = hanja_word::HANJA_SPECIAL.lines()
        .filter_map(|line| {
            let parts: Vec<&str> = line.split(',').collect();
            if parts.len() == 2 {
                let key_str = parts[0].trim().to_string();
                let val_str = parts[1].trim().to_string();
                Some((key_str, val_str))
            } else {
                None
            }
        })
        .collect::<HashMap<String, String>>();  

    Ok((char_dic, dueum_dic, word_dic))
}


pub fn convert_str(
    input_str:&str,         
    char_dic:&HashMap<char,char>, 
    dueum_dic:&HashMap<char,char>,
    word_dic:&HashMap<String, String>) -> Option<String>{

    //1. obtain char array from input_str
    let mut c_iter = input_str.chars().peekable();           

    // 2. convert to hangul 
    let mut buf:String = String::new(); 
    let mut is_exist_chi:bool = false;     
    loop {    
        //2.1 pick a word only contains chinese character
        let mut word:String = String::new();   
        let mut tmp_iter = c_iter.clone();
        while let Some(c) = tmp_iter.peek() {
            if is_chi(&c) {word.push(*c); tmp_iter.next();}
            else {break;}
        }

        //2.2 if 'word' is not empty, check whether it is in the word_dic or not.
        //    if exist, append the value to w_buf and continue.
        //    if not, revert the c_iter and continue.
        if word.len() > 0 {
            match word_dic.get(&word) {
                Some(val) => {
                    buf.push_str(val); 
                    is_exist_chi = true; 
                    c_iter = tmp_iter; // Move the main iterator forward
                    continue;
                },
                None => {}
            }
        }
        
        //2.3 pick a char. if c is None, it's end of file
        let c = match c_iter.next() { 
            Some(ch) => {ch},  None => {break;} 
        };
        let mut new_c = c.clone();

        //2.4 if hanja then convert to hangul else not change       
        if is_chi(&c) {         
            match char_dic.get(&c) {
                Some(val) => {new_c = *val; is_exist_chi = true; },  
                None => {},
            };          

            //2.5. dueum law(두음법칙)
            if let Some(c_peek) = c_iter.peek(){                
                if is_kor_or_chi(&c_peek) { // if next char is exist
                    match dueum_dic.get(&new_c) {
                        Some(ch) => {new_c = *ch;},
                        None => {},
                    }
                }                     
            }          
        }
        buf.push(new_c);
    }
    
    //  if there is no chinese character in the string, return None.
    //   if exist, return the converted string.
    if !is_exist_chi {return None;}
    Some(buf)        
}    

// whether c is chinese character or not
fn is_chi(c:&char) -> bool {
    let n = *c as u32;
    if  (n >= CHI_S1 && n <= CHI_E1) || (n >= CHI_S2 && n <= CHI_E2) || 
        (n >= CHI_S3 && n <= CHI_E3) || (n >= CHI_S4 && n <= CHI_E4) { 
        true 
    }else { false }  
}

// whether c is (korean or chinese character) or not
fn is_kor_or_chi(c:&char) -> bool {
    let n = *c as u32;
    if (n >= KO_START && n <= KO_END) || 
       ( (n >= CHI_S1 && n <= CHI_E1) || (n >= CHI_S2 && n <= CHI_E2) || 
         (n >= CHI_S3 && n <= CHI_E3) || (n >= CHI_S4 && n <= CHI_E4)) {
        true
    }else {
        false
    }    
}

```






